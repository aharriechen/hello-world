{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yixuan chen.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aharriechen/hello-world/blob/master/yixuan_chen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_XVbkYWvnqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjEmdnRGyHjl",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBIvsd81vrNG",
        "colab_type": "text"
      },
      "source": [
        "# **First impression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPcYUQ7gvt0l",
        "colab_type": "text"
      },
      "source": [
        "**What is my chosen paper to read?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTWuqRc-vyvf",
        "colab_type": "text"
      },
      "source": [
        "Generative Adversarial Nets(2014) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGguV5zSv2so",
        "colab_type": "text"
      },
      "source": [
        "**What** **type** **of** **the foremost contribution the paper has made** **?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exsymfwewGn7",
        "colab_type": "text"
      },
      "source": [
        "By learning the joint probability distribution P(X, Y) of samples and observing data samples, the trained model can generate new data for conforming to the sample distribution. Generative adversarial nets can be used for supervised learning and unsupervised learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzvqKL8zwkW3",
        "colab_type": "text"
      },
      "source": [
        "**Before reading the main body of the paper, write down your first impression obtained from its abstract and short introduction.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jksErkCwpyf",
        "colab_type": "text"
      },
      "source": [
        "If you want to train a Generator (Generator, referred to as \"G\"), you can choose from random noise or Latent variables to generate realistic samples. At the same time training a D (Discriminator, referred to as “D”) can identify the real data and generate the data. Both G and D are trained at the same time until a Nash equilibrium is reached. The data generated by the generator is no different from the real sample, and the discriminator cannot correctly distinguish the generated data from the real data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLMaXTCzwuto",
        "colab_type": "text"
      },
      "source": [
        "**Why does the paper attract you? Why do you think it addresses an important topic that will be helpful in your future study of machine learning?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqHX6A68x6Da",
        "colab_type": "text"
      },
      "source": [
        "Because of the popular application of WeChat, an entertainment program can restore old photos, it mainly uses the technology of generative adversarial networks.\n",
        "\n",
        "Generative adversarial nets have become a popular subfield topic in machine learning research and there are many variants. The development of progress is rapidly, and the application in industry is also widely."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y0LRd28yFW4",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 1: report view on \"Generative Adversarial Nets\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-WgEji_yRd7",
        "colab_type": "text"
      },
      "source": [
        "**Introduction** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NayK-56MyhnX",
        "colab_type": "text"
      },
      "source": [
        "In 2014, Goodfellow and his colleagues proposed the concept of the antagonistic generative network for the first time. Since GANs' initiation, it has been widely used in many fields, such as image computing and language processing. GANs' idea is simple, however, a good GAN model needs a lot of skills related to problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhRj3fSiy1zB",
        "colab_type": "text"
      },
      "source": [
        "**Content**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAfa248Ny7zN",
        "colab_type": "text"
      },
      "source": [
        "The main structure of GAN includes a generator (G) and a Discriminator (D). Generation model ‘G' captures the distribution of sample data. It means the input is some random noise that follows a simple distribution (such as Gaussian distribution), and the output is the generated image as the same size as the training image. The discriminant model is a binary classifier to estimate the probability that a sample comes from training data rather than generating data. In a discriminant model, when training data x is input, the result is expected to close to 1. G and D are generally nonlinear mapping functions, such as multilayer perceptrons and convolutional neural networks. For D, it is expected to output a low probability (the judgment result is a generative sample). For G, it is necessary to cheat D as much as possible, the discriminant model output a high probability (the misjudgment is a real sample). There are competition and confrontation.\n",
        "\n",
        "Goodfellow points out that GANs have many advantages, for example, compared with other generative models, GAN does not require a hypothetical data distribution, which means that it does not require formulation p(x). Instead, it adopts a distribution to conduct sampling. Theoretically, it can completely approach the real data, which is GAN's biggest advantage.\n",
        "\n",
        "However, Professor Goodfellow mentioned several problems:\n",
        "\n",
        "Non-convergence problem\n",
        "All the theories suggest that GAN should have an excellent performance in the Nash equilibrium, but only in the case of convex function can gradient decline to guarantee the Nash equilibrium. When both sides of the game are played by neural networks, they are likely to adjust their strategies if there is no equilibrium.\n",
        "Collapse problem\n",
        "GAN model is defined as an extreme value problem without loss function, so it is difficult to distinguish whether progress is being made in the training process or not. If collapse problems occur in the GAN learning process, the generator starts to degenerate and generates the same sample points, then it is impossible to continue learning. When the generated model crashes, the discriminant model points to similar sample points in the same direction, and the training cannot continue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mK-_t2BzYbu",
        "colab_type": "text"
      },
      "source": [
        "**Innovation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0VOrMZXzehS",
        "colab_type": "text"
      },
      "source": [
        "In this paper, the professor puts forward one function, it is the core principle of GAN.and provides a direction for the research of adversarial generation network. This might be the innovation in this paper.\n",
        "\n",
        "The generative adversarial net was inspired by the zero-sum game. In a two-player zero-sum game, the sum of the interests of two players is zero or a constant. It means one gains something and the other loses something. Generated model and the discriminant model were respectively playing the two-game roles in the GANs model.\n",
        "\n",
        "GAN model has no loss function, and the optimization process is a \"minimax two-player game\".\n",
        "\n",
        "![替代文字](https://www.msra.cn/wp-content/uploads/news/blogs/2017/05/images/gan-20170511-3.jpg)\n",
        "\n",
        "This is the Value Function of discriminating network D and generating network G. The training network D corresponds to the label of the training sample with maximum probability (maximizes log D(x)). The training network G minimizes log(1 - D(G(z)), it means the maximizes loss of D. During the training process, one party is fixed, another network parameter is updated, and the error of the other party is maximized by alternating iterations. Finally, G can estimate the distribution of sample data. Generation model G implicitly defines a probability distribution Pg, which we expect to converge to the real data distribution Pdata. The paper proves that this minimum-maximization game has an optimal solution, when Pg = Pdata, Nash equilibrium is reached. Therefore, the generated model G recovers the distribution of training data and the accuracy of discriminating model D is equal to 50%. In this case, we have achieved our goal: we have a generative model G, which can be used to generate images.\n",
        "\n",
        "The author thinks that the advantage of this treatment is to use unlabeled data to distribute the learning samples, which can assist the training process in supervised learning. Experimental results show that the discriminant model trained by this method has a better effect than other methods in the rational utilization of unlabeled data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbAYgQytz5EJ",
        "colab_type": "text"
      },
      "source": [
        "**Technical quality**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnwMznHp02rJ",
        "colab_type": "text"
      },
      "source": [
        "This paper introduces the overall situation of GAN. After reading this paper, I believe it is a high-quality paper. Firstly, it is clear in logic and order. Secondly, the argumentation process is extremely rigorous. All the arguments mentioned in the passage are explained in detail, and third, the sources cited in the passage are very clear. Finally, search results show that the \"Gan\" paper has been cited more than 10,000 times. It indicates this paper is highly technical and valuable. The article is divided into seven sections with additional references. It ensures that each part has a specific description and logical coherence, each formula has a mathematical calculation to prove. It is convenient for readers to understand the author's ideas.\n",
        "\n",
        "However, the paper also has shortcomings. For example, it does not mention how to optimize and improve the GAN model.  People who have used GAN should know that there are many headaches problems in training GAN. For example, GAN training is particularly sensitive to hyperparameters and requiring careful design. Of course, the improvement of GAN also keeps emerging, like WGAN(Wasserstein Generative Adversarial Nets)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXZpmixb1Sq1",
        "colab_type": "text"
      },
      "source": [
        "**Application and X-factor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCtS1yzW1Xr1",
        "colab_type": "text"
      },
      "source": [
        "This paper in the field of neural networks has aroused great response since it was published. This paper is worth reading. But I think the GAN model still has some shortcomings. No pre-modeling is the biggest advantage of GAN. However, this method is too random. For the case of larger images and more pixel, the method based on simple GAN is not easy to control. In Goodfellow's paper, the updating process of learning parameters is set as D updates n times and G updates 1 time, which is also out of similar considerations.\n",
        "\n",
        "In my opinion, if GAN is only used to generate some pictures like real picture samples, it should not receive great attention. For machine learning researchers, GAN should be used to fit data distribution. What is the fitting data distribution? It gives you a training data and you can generate some data like this data distribution through GAN. Having the idea of fitting data distribution and working on data distribution, it is the quality of a real machine learning researcher. A GAN generation paper with good quality which is centering on GAN and focus on a lot of debugging by engineers and the enrichment of neural network architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fedH-Zt1jQP",
        "colab_type": "text"
      },
      "source": [
        "**Presentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gblX4TNS1m49",
        "colab_type": "text"
      },
      "source": [
        "In my opinion, the structure of this paper is reasonable. Firstly, the background of the antagonism generation network is introduced, followed by a detailed elaboration. Subheadings also appear for easy reference. Mathematical formulas and chart experiments are interspersed to prove the correctness of this thesis. However, frequent mathematical formulas are not convenient for those who do not know much about mathematics to study this article. However, the content and knowledge mentioned in this article are not mentioned more in the open class on the Internet.\n",
        "\n",
        "Overall, this is a high-quality paper. It is convenient for future researchers to improve the accuracy of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcxQVd_D2Fmo",
        "colab_type": "text"
      },
      "source": [
        "**Reference**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93tAlb232LaV",
        "colab_type": "text"
      },
      "source": [
        "Goodfellow, Ian J., Pouget-Abadie, Jean, Mirza, Mehdi, Xu, Bing, Warde-Farley, David, Ozair, Sherjil, Courville, Aaron C., and Bengio, Yoshua. Generative adversarial nets. NIPS, 2014.\n",
        "\n",
        "Wasserstein GAN，https://arxiv.org/abs/1701.07875"
      ]
    }
  ]
}